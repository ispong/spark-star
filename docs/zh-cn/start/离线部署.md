##### 使用前提

###### 配置系统环境变量

```bash
sudo vim /etc/profile

# === sudo vim /etc/profile ===
export HADOOP_HOME=/data/cdh/cloudera/parcels/CDH/lib/hadoop
export SPARK_HOME=/data/cdh/cloudera/parcels/CDH/lib/spark


export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH:/opt/cloudera/parcels/CDH/jars
# === sudo vim /etc/profile ===

source /etc/profile
```


> Note:
> 在spring项目中运行yarn模式，无法读取core-site.xml、yarn-site.xml、mapred-site.xml、hdfs-site.xml这四个文件

###### 方法1

```bash
# 或者 git clone https://gitee.com/ispong/spark-star.git
git clone https://github.com/ispong/spark-star.git
# 构建插件
cd star-plugin && mvn clean package
# 添加hadoop配置文件
cd target && mkdir build && unzip star-plugin.jar -d ./build
cp ${HADOOP_HOME}/etc/hadoop/* ./build/BOOT-INF/classes/
cd ./build/ && jar -cvfM0 star-plugin.jar ./
# 运行jar
java -Xbootclasspath/a:
/opt/cloudera/parcels/CDH/jars/json4s-core_2.11-3.5.3.jar
/opt/cloudera/parcels/CDH/jars/jersey-container-servlet-core-2.27.jar
/opt/cloudera/parcels/CDH/jars/jackson-module-scala_2.11-2.9.8.jar
/opt/cloudera/parcels/CDH/jars/jackson-databind-2.9.8.jar
/opt/cloudera/parcels/CDH/jars/lz4-java-1.5.0.jar
/opt/cloudera/parcels/CDH/jars/xbean-asm6-shaded-4.8.jar
/opt/cloudera/parcels/CDH/jars/json4s-jackson_2.11-3.5.3.jar
/opt/cloudera/parcels/CDH/jars/univocity-parsers-2.7.3.jar
/opt/cloudera/parcels/CDH/jars/scala-reflect-2.11.12.jar
/opt/cloudera/parcels/CDH/jars/antlr4-runtime-4.7.jar 

java -jar star-plugin.jar --spring.config.location=./application.yml 

java -Djava.ext.dirs=/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext:/opt/cloudera/parcels/CDH/jars/  -jar star-plugin.jar --spring.config.location=./application.yml 
```

###### 方法2

```bash
# 或者 git clone https://gitee.com/ispong/spark-star.git
git clone https://github.com/ispong/spark-star.git
# 添加hadoop配置文件
cd star-plugin && cp ${HADOOP_HOME}/etc/hadoop/* ./star-plugin/src/main/resources/
# 构建插件
mvn clean package
java -jar ./target/star-plugin.jar
```


##### 调用接口

- http://39.103.230.188:30166

```http request
###
POST http://39.103.230.188:30156/spark-star/executeSql
Content-Type: application/json

{
   "sql":"select * from rd_dev.ispong_table",
   "hasReturn":true
}
```
