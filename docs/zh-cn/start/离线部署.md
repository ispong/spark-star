##### 使用前提

###### 配置系统环境变量

```bash
sudo vim /etc/profile

# === sudo vim /etc/profile ===
export HADOOP_HOME=/data/cdh/cloudera/parcels/CDH/lib/hadoop
export SPARK_HOME=/data/cdh/cloudera/parcels/CDH/lib/spark
# === sudo vim /etc/profile ===

source /etc/profile
```


> Note:
> 在spring项目中运行yarn模式，无法读取core-site.xml、yarn-site.xml、mapred-site.xml、hdfs-site.xml这四个文件

###### 方法1

```bash
# 或者 git clone https://gitee.com/ispong/spark-star.git
git clone https://github.com/ispong/spark-star.git
# 构建插件
cd star-plugin && mvn clean package
# 添加hadoop配置文件
cd target && mkdir build && unzip star-plugin.jar -d ./build
cp ${HADOOP_HOME}/etc/hadoop/* ./build/BOOT-INF/classes/
cd ./build/ && jar -cvfM0 star-plugin.jar ./
# 运行jar
java -jar ./target/build/star-plugin.jar
```

###### 方法2

```bash
# 或者 git clone https://gitee.com/ispong/spark-star.git
git clone https://github.com/ispong/spark-star.git
# 添加hadoop配置文件
cd star-plugin && cp ${HADOOP_HOME}/etc/hadoop/* ./star-plugin/src/main/resources/
# 构建插件
mvn clean package
java -jar ./target/star-plugin.jar
```


##### 调用接口

- http://39.103.230.188:30166

```http request
###
POST http://39.103.230.188:30156/spark-star/executeSql
Content-Type: application/json

{
   "sql":"select * from rd_dev.ispong_table",
   "hasReturn":true
}
```
