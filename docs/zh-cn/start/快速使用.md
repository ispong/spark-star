#### 安装插件

##### 配置环境变量

```bash
sudo vim /etc/profile

# === sudo vim /etc/profile ===
export SPARK_HOME=/opt/cloudera/parcels/CDH/lib/spark
export HADOOP_HOME=/opt/cloudera/parcels/CDH/lib/hadoop

export SPARK_STAR_HOME=/opt/spark-star
export PATH=$PATH:$SPARK_STAR_HOME/bin
# === sudo vim /etc/profile ===

source /etc/profile
```

##### 下载源码

```bash
git clone https://github.com/ispong/spark-star.git
```

###### 修改依赖版本

```bash
vim spark-star/star-plugin/pom.xml
```

- cdh6.2.0

```xml
<properties>
    <spark.version>2.4.0-cdh6.2.0</spark.version>
    <scala.version>2.11</scala.version>
    <hive.version>2.1.1-cdh6.2.0</hive.version>
    <hadoop.version>3.0.0-cdh6.2.0</hadoop.version>
</properties>
```

- spark

```xml
<properties>
    <spark.version>3.1.1</spark.version>
    <scala.version>2.12</scala.version>
    <hive.version>3.1.2</hive.version>
    <hadoop.version>3.2.2</hadoop.version>
</properties>
```

##### 构建源码

```bash
cd spark-star
sudo chmod a+x ./build.sh
sudo -E ./build.sh --prefix=/opt
```

#### 配置文件

```bash
vim /opt/spark-star/conf/application-star.yml
```

```yaml
server:
  port: 30156
  servlet:
    context-path: /spark-star

logging:
  group:
    star: com.isxcode.star
  level:
    star: debug

star:
  plugin:
    server-key: star-key
    app-name-prefix: spark-star
    master: yarn
    spark-config:
      spark.ui.port: 30128
      spark.executor.memory: 4g
      spark.executor.cores: 1
      spark.driver.memory: 1g
      spark.num.executors: 1
      hive.metastore.uris: thrift://192.168.66.66:9083
#      spark.sql.hive.metastore.jars: /u01/cloudera/parcels/CDH/lib/hive/lib/*
#      spark.sql.hive.metastore.version: 2.1.1
#      spark.sql.storeAssignmentPolicy: LEGACY
#    properties-file: /home/dehoop/spark-star/star/conf/executor.conf
#    kafka-config:
#      bootstrap.servers: 39.103.230.188:30120
#      topic: star-topic
#      replication.factor: 1
#      partitions: 1
```

##### 启动插件

```bash
spark-star stop
spark-star start
spark-star log
```
